# Remote Sensing Systems {#chapter-template}

You probably know that you are using your very own organic remote sensing system to read this sentence. Our eyes take in information from the world around us by detecting changes in light and relaying that information through the optic nerve into our brains, where we make sense of what we are seeing. As you learned in Chapter 11, this is what constitutes remote sensing - gathering information (“sensing”) without directly measuring or interacting with that information (“remote”). Whereas our eyes are limited to the visible light portion of the electromagnetic spectrum and by the location of our bodies, remote sensing systems use powerful sensors and flight-equipped platforms to paint a broader and deeper picture of the world around us. 


![Figure 1: North and South America as seen from the NASA GOES-1 satellite. Captured from KeepTrack.space via NASA. [Copyright (C) 2007 Free Software Foundation, Inc.](https://fsf.org/)](images/12-GOES_1_earth.png){.center}

Remote sensing systems range in size and complexity from a handheld camera to the Hubble telescope and capture images of areas ranging from a few metres to several kilometres in size. Though devices such as microscopes, x-ray machines, and handheld radios are technically remote sensing systems, the field of remote sensing typically refers to observing Earth on a small spatial scale (1:100 to 1:250,000).

:::: {.box-content .call-out-content}

::: {.box-title .call-out-top}
#### NOTE {-}
:::

<p id="box-text">
Remember, in spatial scale, “small” means a big picture. If you want a refresher on how to read and understand map scales, check out section 2.5 in Chapter 2.
</p>

::::


The surface of the Earth is around 510 million square kilometres, or 323 billion hockey rinks, so as you can imagine, capturing even a small percentage of that area is a daunting task. Recent advancements in astrophysics and aerospace research have allowed us to conceive, build, and launch satellites from all over the globe to measure Earth from space. In fact, no fewer than 27,000 objects, including decommissioned platforms and debris, are currently whizzing through Earth’s orbit at eye-watering speeds of 7 kilometres per second or more (NASA, 2021). The image shown below is a visualization of all these objects in Earth’s orbit. If you are curious about where individual satellites are located, check out “Stuff in Space”, a website that visualizes satellite orbits all over the globe using real-time data. [Click here](http://www.stuffin.space/ "Stuff in Space") to open the webpage on your browser and try clicking some satellites to see their orbit and various parameters such as altitude, velocity, country of origin, and more.

The range of uses for remote sensing platforms are also dazzling in number, allowing us to monitor severe weather events, ocean currents, land cover change, natural disturbances, forest health, surface temperature, cloud cover, urban development, and so much more with high precision and accuracy. In this chapter, we will break down the how and where of remote sensing systems and discover a few different systems used for Earth observation today.


:::: {.box-content .your-turn-content}

::: {.box-title .your-turn-top}
#### Your turn! {-}
:::

<p id="box-text">
  What other “remote sensing systems” can you think of that you use day-to-day?
</p>

::::

line break needed here

:::: {.box-content .learning-objectives-content}

::: {.box-title .learning-objectives-top}

#### Learning Objectives {-}
::: 

1. Break down remote sensing technology into its basic components
2. Understand how different settings and parameters impact remote sensing system outcomes
3. Review the key remote sensing systems used in Canada and around the world for environmental management

::::

### Key Terms {-}

Absorption, aerial, curvature, focus, geostationary, hyperspectral, LiDAR, multispectral, nadir, oblique, orbit, panchromatic, radiometric, reflection, refraction, resolution, spectral, sun-synchronous, thermal

## Optical System Basics

Did you know that about 60% of your genes have a discernible counterpart in genome of a banana (https://unlockinglifescode.org/media/animations/659#660)? Bananas today are usually found in breakfast foods and not commiserating at family reunions, but this doesn’t change the fact that somewhere in history, we shared a common ancestor with them. Much like you and a certain brightly-hued tropical fruit, remote sensing systems contain a number of common components and operate using similar principles despite their difference in looks. In the next two sections, we will discover the technical specs of remote sensing systems that allow them to “see” the images all around us.

### Lenses

Picture the view from a window onto a busy street on a rainy day: you have cars driving by with headlights, traffic lights reflecting off a wet road, raindrops pouring down the windowpane and distorting the view, and hundreds of people and objects on the street scattering light beams in every possible direction from a huge range of distances. In order for us to take in any of this, these light beams need to reach the retina, the photosensitive surface at the very back of the eye. Seems a bit overwhelming – how do our relatively tiny eyeballs take in all that disparate light and produce crystal clear images for our brains? By using one of the most basic components of any optical system: a lens. A lens is a specially shaped piece of transparent material that, when light passes through it, changes the shape and direction of light waves in a desired way. 


:::: {.box-content .call-out-content}

::: {.box-title .call-out-top}
#### NOTE {-}
:::

<p id="box-text">
The property of transparent mediums to change the direction of light beams is called **refraction**, or transmittance. This is why objects in moving water look all wibbly and misshapen. The arrangement of molecules within a medium disrupts both the direction and speed of the photons – the measurement of this disruption is called the refractive index.]
</p>

::::


The lens at the front of your eyeball changes refracts light beams from varying distances precisely onto your retina. The optical systems on remote sensing platforms are the same: they use a specially designed lens to focus light beams at the desired distance to onto their own recording medium. Below is a simple visualization of how optical systems focus light onto a desired point to produce an in-focus image.


![Figure 2: selected material from [How Focus Works](https://www.bhphotovideo.com/explora/photography/tips-and-solutions/how-focus-works). Copyright Todd Vorenkamp. Used with permission.](images/12-focus_example_humaneye.gif){.center}

Now, picture another scene: you are scrolling through social media and you see a beautiful photo of Mt Assiniboine taken by your friend, a professional photographer based in the Canadian Rockies. You think to yourself, “Wow, that peak looks ENORMOUS! I want to visit there and see it for myself.” So, you ask your friend exactly where they went, drive to Banff National Park, hike to the very same spot, and squint skywards. Hmm…though the mountain is still imposing, it is certainly not towering over you at close range as it was in the photo. You also notice that there are several surrounding peaks that you couldn’t see before. Your friend’s picture was crystal-clear, and you have 20/20 vision, so you know its not an issue with focusing properly. Are you being deceived?

Actually, yes, you are – by both your eyes *and* the camera your friend used. We like to think that our eyes show us the world as it truly is and that everything else is a facsimile, but in truth, all optical systems alter the scenes around us to show us what we need to see. From an evolution standpoint, you can see why clear resolution of close-range objects would be of vital importance for humans – think distinguishing edible plants from poisonous ones, hunting prey, reading facial expressions, etc. We can make out human-sized objects up to a distance of three kilometres in good lighting (https://www.livescience.com/33895-human-eye.html), but if you are interested in seeing something far away, such as a mountainside or a celestial body, you’ll have to trade in your natural close-range viewing abilities for a system specialized for distant details – e.g., binoculars or a telescope. The distance at which objects can be resolved and how they appear in an image lies with the lens – read on below to learn about how different lens designs influence the appearance of a scene or object, and keep in mind how these designs may be used in various earth observation applications.

Most, if not all, lenses on optical systems for remote sensing are **spherical lenses**, called that because each side of the lens is spherical in shape, similar to a bowl. A **convex** optical surface curves outward from the lens centre, whereas a **concave** optical surface curves inward toward the lens centre. Though not spherical, a **planar** or flat optical surface may be used as well. The *radius of curvature* is the measure of how much an optical surface “bulges” or “caves”. If you imagine tracing the edge of the surface in an arc and continuing the curve all the way around in a circle, the radius of this imagined circle would be the radius of curvature. You can get a relative measure of how “curvy” or flat a physical lens is by dividing the radius of curvature by the radius of the physical lens itself – that, one half the height of the physical lens. A very curvy lens approximating a hemisphere would result in a value close to one; a flatter lens would result in a value close to zero. Figures 3a and 3b demonstrate how the radius of curvature is measured for both concave and convex optical surfaces.

![Figure 3a: Measuring the radius of curvature for a convex optical surface. Claire Armour. [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)](images/12-RoC_convex.png){.center}

![Figure 3b: Measuring the radius of curvature for a concave optical surface. Claire Armour. [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)](images/12-RoC_concave.png){.center}



:::: {.box-content .your-turn-content}

::: {.box-title .your-turn-top}
#### Your turn! {-}
:::

<p id="box-text">
  What is the radius of curvature for a perfectly flat lens?
</p>

::::


A spherical lens is formed by joining two optical surfaces – concave, convex, and/or planar – back-to-back. A **biconvex** or positive lens is two convex surfaces, and a **biconcave** or negative lens is - you guessed it - two concave surfaces. Biconvex and biconcave lenses can be “equiconvex”, meaning they have the same spherical curvature on each side, but may also have uneven curvatures. The lens in the human eye is an example of a non-equiconvex lens – our radius of curvature is higher at the front. **Meniscus** lenses have one convex surface and one concave surface. A positive meniscus lens has a flatter concave surface and is thickest in the middle; a negative meniscus lens has a flatter convex surface and is thinnest in the middle. These lenses are commonly found in corrective eyeglasses. An equiconvex meniscus would, in theory, cancel out all refraction. In reality, all lenses have *some* material in between the two surfaces, so there is still refraction occurring in very small amounts. The flowchart in Figure 4 shows how each of these main lenses are related by their optical surfaces and radii of curvature.

![Figure 4: Classifying lenses. Text and flowchart by Claire Armour. [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/). [Lens shape diagrams]([CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)) adapted from [User:elfQrin](https://commons.wikimedia.org/w/index.php?title=User:ElfQrin&action=edit&redlink=1).[CC BY 3.0 Unported](https://creativecommons.org/licenses/by/3.0/) ](images/12-lens_classification_diagram.png){.center}

### Focal Length

So, now that we know a little bit about what lenses look like, its time to figure out exactly how influence an image’s journey from the front of the lens to the recording medium. As you might expect, different combinations of optical surfaces and radii of curvature will behave in different and sometimes unusual ways. Remember that for an image to be in-focus, we need to ensure the light beams are landing precisely on the recording medium or screen.

**Convex optical surfaces cause light beams to *converge*, or focus, to a point behind the lens.** 

**Concave lenses cause light beams to *diverge*, or spread out, resulting in the light appearing to converge (focus) to a point in front of the lens.** 

The point where the light converges or appears to converge is called the *focal point*, and the distance between the focal point and the centre of the lens is called the *focal length*. For a converging lens, the focal length is positive; for a diverging lens, it is negative. Figures 5a and 5b illustrate the behaviour of light when travelling through a biconvex and biconcave lens. See the paragraph below the diagrams for variable labels.

![Figure 5a: Measurements in a biconvex lens. [User:DrBob](https://en.wikipedia.org/wiki/User:DrBob). [CC BY 3.0 Unported](https://creativecommons.org/licenses/by/3.0/)](images/12-convex_focal_diagram.png){.center}

![Figure 5b: Measurements in a biconcave lens. [User:DrBob](https://en.wikipedia.org/wiki/User:DrBob). [CC BY 3.0 Unported](https://creativecommons.org/licenses/by/3.0/)](images/12-concave_focal_diagram.png){.center}


:::: {.box-content .your-turn-content}

::: {.box-title .your-turn-top}
#### Your turn! {-}
:::

<p id="box-text">
Quite frequently, lenses are misshapen, either at birth or becoming so over time. This prevents the lens from precisely redirecting light on the retina, and our world goes out-of-focus. A good optometrist can precisely locate where your lenses aren’t measuring up and provide you with a stylish pair of inorganic lenses to correct this so-called refraction infraction. 
If you can pick the words to form the correct statements below, they may give you 10% off:
If the lens is too *narrow*/*wide*, the beams converge *in front of*/*behind the retina*, causing near-sightedness
If the lens is too *narrow*/*wide*, the beams converge *in front of*/*behind the retina*, causing far-sightedness.]

</p>

::::


The optical power of a lens – the degree to which it can converge or diverge light – is the reciprocal of focal length. Essentially, a “powerful” lens will be able to refract light beams at sharper angles from the horizontal, causing them to converge or appear to converge closer to the lens, i.e., at a smaller focal length. The **Lensmaker’s Equation** (Equation 1) allows us to calculate the focal length ($f$) and/or optical power ($\frac{1}{f}$) as a function of the radii of curvature ($R$), the thickness of the lens between the optical surfaces ($d$), and the refractive index of the lens material ($n$).Note that $R_1$ is the front surface - the side of the lens closest to the origin of the light - and $R_2$ is the back surface.

Equation 1:     \[\frac{1}{f} = (n-1)[\frac{1}{R_1} - \frac{1}{R_2} + \frac{(n-1)d}{nR_1R_2}]\] 


Its important to note the use of sign conventions when it comes to lenses - positive and negative lens types, positive and negative menisci, positive and negative focal length, etc.  This is because these parameters are *scalar* - both the direction and magnitude matter. Unfortunately, the naming conventions can be a little confusing, so you can refer to these rules to be sure:


1. If the surface curves **toward** the origin of the light, it has a **positive** radius of curvature.
*Examples: a convex surface on the front of the lens or a concave surface on the back of the lens.*
2. If the surface curves **away from** the origin of the light, it has a **negative** radius of curvature.
*Examples: a concave surface on the front of the lens or a convex surface on the back of the lens.*
3. If light converges or appears to converge **behind** the lens, the focal length is **positive**.
*Examples: a biconvex, plano-convex lens, or positive meniscus lens.*
4. If light converges or appears to converge **in front of** the lens, the focal length is **negative**.
*Examples: a biconcave, plano-concave lens, or negative meniscus lens.*
5. The **sign of a meniscus lens** is always the **same as its focal length** (see #3 and #4)
6. Optical power and focal length always have the same sign.

[This Wolfram-Alpha demonstration](https://demonstrations.wolfram.com/LensmakersEquation/#embed) allows you to manually adjust the parameters of the Lensmaker's Equation and see the outputs. Have a go and test yourself on the rules!

We know how lenses impact focal length, but how does focal length impact a photo? Let us return to our scenario in Banff National Park where we have two mismatched images of the same mountain. You’ve done some investigating and found that the camera your friend used is very large (and expensive). The lens at the front is quite far from the recording medium in the body of the camera – many times the distance between your own eye lens and recording medium, the retina. This difference in focal length is the cause of the differing images. A low optical power lens with a long focal length will have high magnification, causing distant objects to appear larger and narrowing the area we can see. A high optical power lens with a short focal length, such as your eye, will have low magnification and a larger area we can see by comparison. Mystery solved!



:::: {.box-content .your-turn-content}

::: {.box-title .your-turn-top}
#### Your turn! {-}
:::

<p id="box-text">
  When you return from your trip, your friend decides to test you on your new skills and shows you these additional photos they took of Mt Assiniboine in nearly identical spots on the same day. They ask you which photo was taken with a longer camera lens. How can you know? Try this: from the peak of Mt Assiniboine (the very big one), draw a line straight downwards or cover half of the photo with a piece of paper, and then do the same for the other photo. Does the line or paper edge intersect at the same points of the foreground in each photo? Can you see the same parts of the mountains in the foreground? Use the rock and snow patterns for reference. If the cameras were the same focal length, even with different cropping and lighting as seen here, the answers should both be yes. Can you tell which photo was taken with a 67mm lens and which was taken with a 105mm lens? See the captions for the answer!
  
  ![Figure 6a: Mt Assiniboine on a 67mm lens. Kyle Maguire. [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)](images/12-assiniboine_day.jpg){.center}
  
   ![Figure 6a: Mt Assiniboine on a 105mm lens. Kyle Maguire. [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)](images/12-assiniboine_sunset.jpg){.center}
  
  
</p>

::::



### Principle Points

:::: {.box-content .your-turn-content}

::: {.box-title .your-turn-top}
#### Your turn! {-}
:::

<iframe width=100% height=800px src='https://paulpickell.ca/scenejs-test/' frameBorder="0" >
  <p>Your browser does not support iframes</p>
</iframe>

::::

## Second Section Header

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Ut in dolor nibh. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Praesent et augue scelerisque, consectetur lorem eu, auctor lacus. Fusce metus leo, aliquet at velit eu, aliquam vehicula lacus. Donec libero mauris, pharetra sed tristique eu, gravida ac ex. Phasellus quis lectus lacus. Vivamus gravida eu nibh ac malesuada. Integer in libero pellentesque, tincidunt urna sed, feugiat risus. Sed at viverra magna. Sed sed neque sed purus malesuada auctor quis quis massa. 

:::: {.box-content .case-study-content}

::: {.box-title .case-study-top}
#### Case Study {-}
:::

#### Case study title max of forty characters {#box-text -}

<p id="box-text">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Praesent non magna non nunc auctor eleifend. Etiam fringilla fermentum nisl at volutpat. Duis sodales lorem interdum, posuere neque sollicitudin, malesuada nisl. Sed laoreet commodo dui et cursus. Curabitur vel porta mauris. In lacinia ac ex ac varius. Nullam at vulputate ligula. Nunc sed faucibus urna, eget placerat sapien. Fusce ut lorem a ante congue consequat et sed tortor. Integer neque urna, vehicula at aliquam non, luctus non mi. Pellentesque et massa vehicula, cursus erat id, aliquet sapien. Sed rhoncus vehicula risus, vel aliquam eros porta eget. Etiam maximus, massa in pretium semper, est libero feugiat ipsum, quis tempor nunc libero in nibh. Nunc sollicitudin mattis metus ut rutrum. Donec urna purus, sodales id nibh in, ultricies tincidunt nibh. Proin porta accumsan aliquet.</p>

<p id="box-text">Cras convallis erat ante, ut tristique est tempor elementum. Nam mollis, ipsum at vehicula vestibulum, est magna finibus nisl, et laoreet metus massa et ipsum. Proin eget eros ac odio euismod volutpat et ac diam. Cras viverra ut libero vel pulvinar. Duis nisi magna, sagittis id ligula ac, efficitur commodo eros. Nulla tincidunt id nulla in lobortis. Sed non mi eu mi fermentum cursus. In elit velit, semper sed gravida at, imperdiet sed nibh. Aliquam quis massa malesuada, venenatis nunc sed, malesuada nulla. Vestibulum malesuada purus ut ex ullamcorper, ut blandit lacus lobortis. Curabitur scelerisque velit justo, quis porttitor purus efficitur ut. Phasellus nec arcu vestibulum, consequat ante id, elementum velit. Proin arcu tortor, cursus vitae sem id, congue semper urna. Integer tempus in est eu consequat. Donec sodales, quam vel finibus faucibus, leo ante dictum quam, id tempus ligula dolor quis erat. Curabitur non elementum sem. Mauris placerat fermentum orci non lacinia. Ut imperdiet dui lectus, ac malesuada felis euismod sed. Nulla non volutpat dui, in suscipit turpis.</p>

<p id="box-text">Case studies should have at least one image or map (no more than 2 total) and the written length should be around 300 words (shown above). Any references to external literature should by hyperlinked with the Digitial Object Identifier (DOI) permanent URL and [entered into the bibliography](https://bookdown.org/yihui/bookdown/citations.html){target="_blank"}. Avoid linking to external resources without a DOI and permanent URL. Contact Paul or try using the Leaflet package in R if you want to add an interactive web map.</p>

::::

## Third Section Header

[This is how we link to something. {target="_blank"} ensures that this link opens in a new window rather than navigating away from the textbook.](https://google.com){target="_blank"}

:::: {.box-content .your-turn-content}

::: {.box-title .your-turn-top}
#### Your turn! {-}
:::

<p id="box-text">Ask the reader to undertake some activity or exercise. Have them explore data, an interactive tool, a web map. Avoid referencing, relying on, or using external URLs. If it can be built, coded, or hosted by us, then it should be.</p>

<iframe width=100% height=800px src='http://paulpickell.ca/raster-calculator/low-pass-filter.html' frameBorder="0" >
  <p>Your browser does not support iframes</p>
</iframe>

::::

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Ut in dolor nibh. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Praesent et augue scelerisque, consectetur lorem eu, auctor lacus. Fusce metus leo, aliquet at velit eu, aliquam vehicula lacus. Donec libero mauris, pharetra sed tristique eu, gravida ac ex. Phasellus quis lectus lacus. Vivamus gravida eu nibh ac malesuada. Integer in libero pellentesque, tincidunt urna sed, feugiat risus. Sed at viverra magna. Sed sed neque sed purus malesuada auctor quis quis massa.

:::: {.box-content .call-out-content}

::: {.box-title .call-out-top}
#### Call out {-}
:::

<p id="box-text">
This is a call out. Put some important concept or fact in here.
</p>

::::

## Summary

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Ut in dolor nibh. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Praesent et augue scelerisque, consectetur lorem eu, auctor lacus. Fusce metus leo, aliquet at velit eu, aliquam vehicula lacus. Donec libero mauris, pharetra sed tristique eu, gravida ac ex. Phasellus quis lectus lacus. Vivamus gravida eu nibh ac malesuada. Integer in libero pellentesque, tincidunt urna sed, feugiat risus. Sed at viverra magna. Sed sed neque sed purus malesuada auctor quis quis massa.

### Reflection Questions {-}

1. Explain ipsum lorem.
2. Define ipsum lorem.
3. What is the role of ispum lorem?
4. How does ipsum lorem work?

### Practice Questions {-}

2. Given ipsum, solve for lorem.
3. Draw ipsum lorem.

`r if (knitr::is_html_output()) '
## Recommended Readings {-}
'`

Ensure all inline citations are properly referenced here.

```{r include=FALSE}
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown', 'htmlwidgets', 'webshot', 'DT',
  'miniUI', 'tufte', 'servr', 'citr', 'rticles'
), 'packages.bib')
```
