[["chapter-template.html", "Chapter 3 Fundamentals of remote sensing 3.1 What is remote sensing? 3.2 Types of Energy 3.3 Physical laws of radiation 3.4 The Four Resolutions 3.5 Key applications 3.6 Summary", " Chapter 3 Fundamentals of remote sensing At some point in your life you may have wondered why the sky is blue. You may have noticed that two leaves on the same tree are slightly different shades of green. It would be perfectly natural to wonder these things and simply allow the questions to remain unanswered. After all, they likely carry minimal significance compared to the other queries of your life. What if, however, these questions could not only be answered, but also lead you to profound insights relating to your environment? What if differences in leaf color indicated an early summer drought or the initial stages of a pest outbreak that would wreak havoc on the economy? Remote sensing is the overarching term that refers any scientific exploration that seeks to address these, and many other questions. Learning Objectives Understand key principles underpinning remote sensing science Become familiar with specific types of energy used in RS Define key interactions between energy and surface materials that enable RS Comprehend various considerations that effect the use of RS Key Terms Radiation, Energy, Photons, Electromagnetic Spectrum, Wavelength, Resolution, Raster, Image, Pixel 3.1 What is remote sensing? Simply put, remote sensing is any method of gathering information about an object, or objects, without physical contact. Over the course of human history, a variety of remote sensing techniques have been used. In fact, one could argue that any organism capable of observing electromagnetic radiation has a built in optical remote sensing system, such as human vision. Similar arguments could be made for other senses, such as smell or hearing, but this chapter will focus strictly on techniques that capture and record electromagnetic radiation. The first recorded use of optical remote sensing occurred ____ (Plato). Over the next few centuries a variety of photosensitive chemicals were discovered and, in ____, ______ established the technique recognized as photography. The ability to record specific objects within a scene proved enabled the preservation of information in a rapid and accessible medium. Eventually, photography became a prominent means of immortalizing everything from individual humans to exotic landscapes. After all, a picture says a thousand words. In 1851, an enthusiastic Frenchman named Gaspard Tournachon mounted a camera on a hot air balloon and captured images of the earth below him. These images were taken as the camera looked straight down, or nadir, at the City of ___ and provided a novel view of the city. For the first time it was possible to examine the distribution of buildings, fields, forests and roads across the landscape. With this, airborne remote sensing was born. Remote sensing technologies continued to advance throughout the 19th and 20th centuries, with major socio-political conflicts like World War I and II acting as crucibles for innovation. The advancement of remote sensing has continued into the 21st century and is unlikely to slow down in the future. This is due to the relevance of three key aspects. First and foremost, remote sensing enables the observation of objects in, or from, locations that are otherwise inaccessible for humans. The observation of Mars surface from an orbiting satellite is a one current example. A second aspect that makes remote sensing so useful is the collection of information over a large area. For example, airborne remote sensing technologies enable observations of land cover across Canada (Figure 1). The ability to evaluate inaccessible objects or large areas over time is a third valuable aspect of remote sensing and is particularly relevant for land management, as predictions can be informed through the observation of historic patterns and processes. This is especially true for projects aiming to restore degraded ecosystems or plan sustainable land use practices. Before exploring the designs of specific sensor or their applications, however, it is essential to grasp some key components that underpin remote sensing science. 3.2 Types of Energy 3.2.1 Introduction Stepping back from remote sensing for a moment, there are three general types of energy commonly used to remotely observe objects: sonic, thermal and electromagnetic. Sonic, or sound, energy is commonly used in environments where heat or light are inconsistent or hard to measure. Sonar is as example of a sonic remote sensing technique and is often deployed to observe objects in liquid. Thermal, or heat, energy is used in a variety of cases when changes in temperature indicate an underlying physiological process. An environmental example would be the observation of plant health via leaf temperature. Although both sonic and thermal energies provide useful information across a variety of disciplines, they are not the most common. Electromagnetic radiation (EMR), which is what the human sense of sight observes, is a popular energy source in remote sensing science. At its most basic, this method of observation is based on the measurement of photons. Research using EMR is fundamentally interested in examining the interactions of EMR, or photons, and other particles. Before diving into the applications of EMR remote sensing (photography, spectroscopy, etc.) it is important to understand some basic theory regarding the measurement of photons. Essentially, photons are the smallest physical property in the electromagnetic field. Photons can be emitted from objects engaged in nuclear processes (such as the sun), objects excited thermally (like a light bulb) or objects that reflect or emit absorbed radiation. The interactions between emitted photons and other particles can be observed and used to evaluate the properties of the object. A fundamental component of EMR is its wavelength, defined as the measured space between two consecutive peaks of a wave (IMAGE). The wavelength of a photon determines if and how it will interact with the particles around it, as well as defines the amount of energy it has. Measuring the differences in photonic energy before and after interacting with another particle is the core of any remote sensing utilizing EMR. Perhaps the simplest path to understanding how the properties of photons (i.e. energy, wavelength) are used for remote sensing purposes is through the use of an equation. Albert Einstein explained the energy of a photon as the product of its wave frequency (the number of waves that pass a specific point over a certain amount of time) and Plancks constant (Equation 1). Equation 1 \\[ E = hf \\]Where E is the energy of a photon, h is Plancks constant (h = 4.14 Ã— 1015 eV/s) and f is the wave frequency. Clearly, an increase in frequency results in an increase of energy. This equation may be altered to include other properties, such as the speed of light and wavelength (Equation 2). Equation 2 \\[ E = hc/ \\]Where E is the energy of a photon, h is Plancks constant, c is the speed of light (c = 3 x108 m/s) and  is the wavelength of the radiation. This equation contains more variables, but incorporates wavelength and in doing so utilizes an easy to measure (hc always equals 1240 eV/nm) and familiar characteristic. Due to the large range of wavelengths that photons can exhibit it is necessary to use a specific style of writing to describe them, called scientific notation. 3.2.2 Scientific Notation Expressing extremely large or small numbers presents a challenge to both efficiency and accessibility that has existed likely since the creation of mathematics. Scientific notation presents a simple solution to this problem through simplifying numeric presentation to a value less than 10 that is raised to a particular power. Put simply, the decimal point of a large or small number is moved to make the smallest, single digit whole number. The number of places and direction that the decimal point moves is described by an associated power of 10. Equations 3 and 4 depict how large and small numbers are presented in scientific notation, respectively. Equation 3 \\[ 1,000,000 = 1.0 X 10^{6} \\] Equation 4 \\[ 0.000001 = 1.0 X 10 ^{-6} \\] 3.2.3 Electromagnetic Spectrum Now that you have an understanding of how the properties of photons can be measured and how to write them, we can begin to explore the electromagnetic spectrum (EMS). The EMS is the continuum along within photons are located based on their properties (Figure 2). We have discussed both wavelength and frequency, which are inversely related and commonly used to describe EMR. Figure 2 also depicts a thermometer laying sideways, which demonstrates that as an objects temperature increases, the wavelength of the photons emitted decreases. This follows Equation 2, which demonstrates that photons with shorter wavelengths have higher energy. A practical example of this would be that the majority of photons emitted from the sun (5,788 K) are around 0.5 x 10-6 nm, while the majority of photons emitted from the human body (~310 K) are around 10-4. Theoretical blackbodies??? Call out Visualizing the electromagnetic spectrum (EMS) in Figure 2 certainly enables a wonderful comprehension of many concepts relating to photons. Perhaps more astounding, however, is the truth of how the faculty of human vision has incorporated these properties. The portion of the EMS that humans can see is between 400 nm and 750 nm, which correlates with the most common wavelengths emitted from the sun (Figure _). Perhaps it should not be surprising, but of all the possible wavelengths emitted in our environment, human eyes have evolved to maximize solar photon emission. 3.2.4 Radiation Types Since it is possible for photon energy to vary widely across the EMS, it can be useful to group photons based on their wavelength. Generally, there are seven accepted categories. it is important to note that these categories have gradual boundaries, rather than sharp dividing lines. In order of increasing wavelength they are: radio, microwave, infrared, visible, ultraviolet, X ray and Gamma ray. We will detail each of these seven groups in Table 1 (Zwinkels 2015). If you wish a visual tour of the EMS you can explore this document created by Ginger Butcher for NASA in 2010. Table 1. Details for the seven regions of the electromagnetic spectrum. Name Wavelength Details Radio 1 cm - 1,000 km (103 - 1010) Microwave 1 mm - 1 cm (1010 - 1011) Infrared (IR) 700 nm - 1 mm (1011 - 1014) Visible (Vis) 400 - 700 nm (1014 - 1015) Ultraviolet (UV) 10 - 400 nm (1015 - 1017) X rays 0.1 - 10 nm (1017 - 1020) Gamma rays &lt; 0.1 nm (1020 - 1023) 3.3 Physical laws of radiation With a solid grasp of why EMR is useful for remote sensing science and how EMR is categorized along the EMS, we can begin to apply this core knowledge with ideas and applications related to practical use. As with radiation, there are a plethora of terms used to describe the fundamental concepts that make remote sensing science possible. Some of the most common terms have been included below. They are organized into three categories: Radiation Basics, Foundations of Measurement and Methods of Normalization. Radiation Basics The use of radiation to quantify properties of an object is inherently linked with relatively complex theories of physics. To minimize both confusion and workload, we will highlight a select number of key concepts that support the use of the EMS for remote sensing (Figure WORKFLOW_). The first concepts to become familiar with are radiant energy and radiant flux Radiant energy is essentially the energy carried by photons, which is measured in Joules (J). Recall that the amount photon energy defines what wavelength (Equation 2). Radiant flux, which is interchangeable with radiant power, is the amount of radiant energy that is emitted, reflected, transmitted or absorbed by an object per unit time. Radiant flux considers energy at all wavelengths and is often measured per second, making its SI Watts (W), which is simply Joules per second (J/s) . Spectral flux is an associate of radiant flux and simply reports the amount of energy per wavelength (W/nm) or (W/Hz). Combined, these two terms allow us to describe the interaction with electromagnetic radiation and its environment; radiant energy interacts with an object, which results in radiant flux. Now that you are familiar radiant energy and flux, we can discuss irradiance. Irradiance refers to the amount of radiant energy that contacts a 1 m2 area each second (W m-2). This includes all electromagnetic energy that contacts our 1 m2 surface, which could be a combination of radiation from the sun, a halogen light bulb overhead and your computer screen. Another important concept is solar irradiance, which strictly refers to the amount of solar radiation interacting with our 1 m2 area. Solar irradiance is very important in many remote sensing applications as it determines which photons an optical sensor could record in naturally illuminated environments. An associate of irradiance is radiance, which refers the the amount of radiant flux is a specific direction. The direction in question is often called the solid angle and makes radiance a directional quantity. You could imagine holding a DLSR camera 90 0 above a flat leaf so that the only item visible to the shutter is the leaf. The camera would capture the radiance reflected from the leafs surface and the solid angle would be 900. Essentially, irradiance is used to measure the radiant energy that contacts a 1 m2 area, while radiance measures the radiant flux of an object from a specific angle. So far we have discussed radiant energy and flux as basic concepts interacting with a single object (leaf) or 1 m2 surface. In reality, radiant energy from the sun begins interacting with objects as soon as it enters earths atmosphere. The process by which radiation is reflected by other particles is called scattering. Scattering occurs throughout the atmosphere and is generally separated into three categories: Rayleigh, Mie and Non-selective. The three categories of atmospheric scattering are defined by the energys wavelength and the size of the interacting particle. When the wavelength of incoming radiation is larger than the particles (gases and water vapor) with which it interacts, Rayleigh scattering occurs. Phenomenon related to Rayleigh scattering include Earths sky appearing blue. When the wavelength of incoming radiation is similar to that of the particles with which it interacts Mie scattering occurs. The size of particles generally considered to similar is between 0.1 - 10 times that of the wavelength. Smoke and dust are common causes of Mie scattering. A third type of scattering occurs when the particles involved are lager than the wavelength of the incoming radiation. This is called non-selective scattering and results in the uniform scattering of light regardless of the wavelength. Examples of non-selective scattering are clouds and fog. The combination of these three scattering types leads to drastic differences between the amount of solar irradiance at the top of the atmosphere and at sea level (Figure __). There are also a variety of wavelengths at which ozone, oxygen, water and carbon dioxide absorb incoming radiation, precluding entire sections of the EMS from reaching the surface. Overall, only a small portion of energy emitted from the sun reaches the Earths surface. Most energy is absorbed or scattered by particles in the Earths atmosphere The process of scattering is also affected by the properties with which it interacts. The angle at which EMR interacts with a surface, as well as the surface material, determine the properties of reflection. A reflector is described based on the properties of EMR that are reflected from it and range from specular to diffuse. Specular reflectance occurs when EMR is reflected in a single direction and can also be called ansiotropic reflectance. A mirror is an example of a specular reflector. A diffuse, or Lambertian, reflector reflects EMR in all directions equally and can also be called an isotropic reflector. An example of a surface that reflects EMR isotropically is paper. Although specular and diffuse are measured on an spectrum four general classifications for reflectors are accepted: perfect specular, near-perfect specular, near-perfect diffuse and perfect diffuse. diffuse surfaces tend to be the most useful for remote sensing as they scatter light in all directions. This is useful because sensors can only view a surface from a single angle and can also be moving. Attempting to determine the angle at which EMR is reflected would make many projects unfeasible, especially those covering large areas. This is not to say that diffuse reflectors are perfect, however, as some issues remain related to the angle of incidence and the position of the sensor. For example, both back scattering and forward scattering affect the amount of radiation that reaches a sensor, depending on where the sensor is located. If a sensor is observing an object at the same angle as the incident radiation, the majority of reflected EMR will be from backscatter, or EMR that is scattered back towards its source. If the object being observed is perfectly specular, no EMR reflected off the object would be captured by the sensor. If the object is a diffuse or near-perfect diffuse reflector, then there is less of a concern with regards to capturing reflected EMR. Foundations of Measurement Now that we have discussed radiant energy and the concepts underpinning its interactions with other objects, we can begin to explore the measurements that our sensors record. One of the most important concepts to understand is that of the spectral signature, or spectra. A spectral signature refers to the amount of electromagnetic energy recorded across a defined section of the EMS. A nice example of a spectral signature is Figure __, which presents the suns radiation between 250 - 2500 nm in the units of solar irradiance (W/m2/nm). Similar graphs are common throughout remote sensing and can employ different units of measure. The base measurements taken to generate spectral signatures is of an objects radiance. Acquiring radiance across a defined section of the EMS can be conducted by a variety of sensors and at different spatial scales, highlighting the practical advantages of evaluating surfaces using EMR. To fully capture and compare the objects being measured, however, it is often necessary to normalize radiance. The need for normalization stems mainly from the aforementioned issues of atmospheric effects, source and sensor location and sensor calibration. As with any normalization, the first step is to identify our minimum and maximum values. There are two common reference measurements used to determine minimum and maximum radiance: dark and white reference. A dark reference is often taken by measuring the amount of energy recorded by a sensor when the input device is ignored. In theory, this would be the internal darkness of the machine and is considered to be the minimum radiance value in practice. The maximum radiance value is slight more challenging to determine as it requires a perfectly diffuse, flat white surface. A commonly used material is Spectralon, which has almost 100% reflectance between 400 - 1500 nm and greater than 95% reflectance over the entire optical region of the EMS (250 - 2500 nm). With both minimum and maximum values defined, it becomes possible to calculate normalized spectral values for a variety of properties across changing conditions. Methods of Normalization Upon calibrating an instrument to both 100% and 0% reflectance, it is possible to determine three normalized measurements of EMR: reflectance, transmittance and absorption. Each of these measurements provides useful information for understanding the interactions between EMR and the environment. Reflectance refers EMR that has interacted with and effectively bounced back. It has emerged as a popular method of evaluating a variety of environmental properties, including land use change, plant health and plant diversity (Asner et al. 2011). Another popular normalized measure of the interaction between photons and a surface is transmittance. A photon that is transmitted has passed through the surface with which it interacted and provides insight regarding how much energy can reach other surfaces below. In a forestry context, this information can be particularly useful when determining the amount of radiation that reaches below the upper canopy (cite LAI, etc.). Absorbance is a third, related measurement that refers to the amount of energy absorbed by the cells within a surface and is equal to the the difference in energy between reflectance and transmittance (Equation 5). \\[ Reflectance - Transmittance = Absorbance \\] Although relatively straight forward, these definitions allow us to start exploring a variety of remote sensing applications. In fact, most optical remote sensing techniques employ at least one of reflectance, transmittance and absorbance to examine the world. Before moving on to the next section, please review the work flow below highlighting what we have learned so far. In our next steps we will move from theory to application and begin to explore the factors that define the quality, and therefore capability, of remotely sensed data. Your turn! Create a workflow of theories to highlight chapter so far Practice questions relating to photon energy: demonstrate the higher frequency = higher energy higher wavelength = lower energy What is the section of the EMS in which humans can see? What is its approximate range? 3.4 The Four Resolutions One of the first considerations any user must make regarding remotely sensed data is its quality. For most scientific research, good quality data needs to contain information that is relevant to the scale and time period of the study. It would be challenging, for example, to evaluate the changes in vegetation cover in Vancouver, B.C. from 2010 - 2020 by looking at a single image of Calgary, Alberta from 1995. Although this example may seem extreme, it highlights the need for data collectors and users to communicate about where, when and what is included in a dataset. Enter the Four Resolutions. 3.4.1 Spatial Resolution Although each resolution is important, spatial resolution holds a key position when determine the usefulness of a dataset as it determines the scale at which information is collected. When a sensor collects information it does so in a single area. That area could be the size of a single tree or a single city, but all the EMR measured by the sensor will be an average of that area. Generally, this area is referred to as a picture element, or pixel. A pixel is the smallest addressable digital element and basic unit of remotely sensed data. When multiple pixels are collected in adjacent areas, perhaps using an instrument with multiple sensors on it, the output is called an image. In short, an image is a collection of pixels, which represent mean values of the area they represent. Spatial resolution, then, is the ground area represented by a pixel. There are a variety of factors that affect spatial resolution, or the size of a pixel. One important factor is the sensors field of view (FOV). A field of view refers to the observable area of a sensor and is defined by two things: the angle of the FOV and the sensors distance from its target. Changes in these two factors result in an increase or decrease in the amount of area captured by a senor and therefore a change in pixel size. Pixels that cover larger areas are considered to have lower spatial resolution, while a relatively smaller pixel is considered high resolution. When a sensor is in motion, collecting multiple pixels across space and time, the term instantaneous field of view (IFOV) is used to describe the FOV at the time each pixel was collected. We will learn more about the challenges of collecting data over space and time in Chapters 12 and 15. To determine if a certain spatial resolution is useful, then it would need to be detailed enough to include the features of interest, but large enough to be stored and processed in a reasonable manner. It must also cover the entire study area, which can vary significantly depending on the research objectives. Each of these considerations will direct the data user to a specific sensor. From here, the user can begin to consider the remaining three resolutions. 3.4.2 Temporal Resolution Much like spatial resolutions deals with the space that a sensor observes, temporal resolution refers to the time interval between successive observations of a given space. Temporal resolution can span seconds or years and is requirement when investigating change. Much like spatial resolution, an acceptable temporal resolution is defined inherently by the nature of the study. For example, a study monitoring the annual urban expansion of Vancouver, B.C. would have a temporal resolution of 1 year. 3.4.3 Spectral Resolution Earlier in this chapter the concepts and theories surrounding EMR were presented. These theories related directly to the concept of spectral resolution, which refers to the number and dimension of specific EMR wavelengths that a remote sensing instrument can measure. Due to the large range of the EMS and properties of EMR, the term spectral resolution is often used to refer to a single component of its definition. In scientific literature, it is not uncommon to find spectral resolution referring to: the number of spectral bands (discrete regions of the EMS) that are sensed as a single unit. the location of these units, or groups of bands, along the EMS. the bandwidth (____) of each band. 3.4.4 Radiometric Resolution defines a sensors capacity to distinguish small differences in energy. 3.5 Key applications Image Interpretation Optical remote sensing Spectral Signatures True Color False Color Airborne Laser Scanning Chapter 15 Case Study: Demo each resolution in relation to an image Case study title max of forty characters Lorem ipsum dolor sit amet, consectetur adipiscing elit. Praesent non magna non nunc auctor eleifend. Etiam fringilla fermentum nisl at volutpat. Duis sodales lorem interdum, posuere neque sollicitudin, malesuada nisl. Sed laoreet commodo dui et cursus. Curabitur vel porta mauris. In lacinia ac ex ac varius. Nullam at vulputate ligula. Nunc sed faucibus urna, eget placerat sapien. Fusce ut lorem a ante congue consequat et sed tortor. Integer neque urna, vehicula at aliquam non, luctus non mi. Pellentesque et massa vehicula, cursus erat id, aliquet sapien. Sed rhoncus vehicula risus, vel aliquam eros porta eget. Etiam maximus, massa in pretium semper, est libero feugiat ipsum, quis tempor nunc libero in nibh. Nunc sollicitudin mattis metus ut rutrum. Donec urna purus, sodales id nibh in, ultricies tincidunt nibh. Proin porta accumsan aliquet. Cras convallis erat ante, ut tristique est tempor elementum. Nam mollis, ipsum at vehicula vestibulum, est magna finibus nisl, et laoreet metus massa et ipsum. Proin eget eros ac odio euismod volutpat et ac diam. Cras viverra ut libero vel pulvinar. Duis nisi magna, sagittis id ligula ac, efficitur commodo eros. Nulla tincidunt id nulla in lobortis. Sed non mi eu mi fermentum cursus. In elit velit, semper sed gravida at, imperdiet sed nibh. Aliquam quis massa malesuada, venenatis nunc sed, malesuada nulla. Vestibulum malesuada purus ut ex ullamcorper, ut blandit lacus lobortis. Curabitur scelerisque velit justo, quis porttitor purus efficitur ut. Phasellus nec arcu vestibulum, consequat ante id, elementum velit. Proin arcu tortor, cursus vitae sem id, congue semper urna. Integer tempus in est eu consequat. Donec sodales, quam vel finibus faucibus, leo ante dictum quam, id tempus ligula dolor quis erat. Curabitur non elementum sem. Mauris placerat fermentum orci non lacinia. Ut imperdiet dui lectus, ac malesuada felis euismod sed. Nulla non volutpat dui, in suscipit turpis. Case studies should have at least one image or map (no more than 2 total) and the written length should be around 300 words (shown above). Any references to external literature should by hyperlinked with the Digitial Object Identifier (DOI) permanent URL and entered into the bibliography. Avoid linking to external resources without a DOI and permanent URL. Contact Paul or try using the Leaflet package in R if you want to add an interactive web map. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Ut in dolor nibh. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Praesent et augue scelerisque, consectetur lorem eu, auctor lacus. Fusce metus leo, aliquet at velit eu, aliquam vehicula lacus. Donec libero mauris, pharetra sed tristique eu, gravida ac ex. Phasellus quis lectus lacus. Vivamus gravida eu nibh ac malesuada. Integer in libero pellentesque, tincidunt urna sed, feugiat risus. Sed at viverra magna. Sed sed neque sed purus malesuada auctor quis quis massa. 3.6 Summary Lorem ipsum dolor sit amet, consectetur adipiscing elit. Ut in dolor nibh. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Praesent et augue scelerisque, consectetur lorem eu, auctor lacus. Fusce metus leo, aliquet at velit eu, aliquam vehicula lacus. Donec libero mauris, pharetra sed tristique eu, gravida ac ex. Phasellus quis lectus lacus. Vivamus gravida eu nibh ac malesuada. Integer in libero pellentesque, tincidunt urna sed, feugiat risus. Sed at viverra magna. Sed sed neque sed purus malesuada auctor quis quis massa. Reflection Questions Explain ipsum lorem. Define ipsum lorem. What is the role of ispum lorem? How does ipsum lorem work? Practice Questions Given ipsum, solve for lorem. Draw ipsum lorem. ## Recommended Readings {-} Ensure all inline citations are properly referenced here. References "]]
